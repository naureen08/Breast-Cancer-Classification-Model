{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![neural](https://media.springernature.com/lw630/nature-cms/uploads/collections/Networks-Collection-img-final-f2c265a59e457f48645e2aa3ff90e942.jpg)\n",
        "\n",
        "##**Breast Cancer Classification with a Neural Network**\n",
        "\n",
        "**By Naureen Hossain**\n"
      ],
      "metadata": {
        "id": "d24aJJZeSmO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Import the Dependencies**"
      ],
      "metadata": {
        "id": "xj-ZhH9NjUG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "31R_NdQxTEXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Data Collection**\n",
        "\n",
        "Scikit Learn is a machine learning library that includes a very simple binary classification data set. The data set classifies breast cancer tumors into malginant and benign.\n",
        "\n",
        "We will import the library using the variable breast_cancer_data"
      ],
      "metadata": {
        "id": "MDP-do7uknef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_data = sklearn.datasets.load_breast_cancer()"
      ],
      "metadata": {
        "id": "_qnby5tBTKNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Loading the Data to a Data Frame**\n",
        "\n",
        "We will load the data into a dataframe using the Pandas library under the variable 'X'. Using the DataFrame function we can load the data (breast_cancer_data.data and set the columns with the feature names from the data (breast_cancer_data.feature_names). We will load the target data under the variable 'Y' to seperate the features from the target.\n"
      ],
      "metadata": {
        "id": "SwZa8zJXkmXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(breast_cancer_data.data, columns = breast_cancer_data.feature_names)\n",
        "Y = breast_cancer_data.target"
      ],
      "metadata": {
        "id": "UpHFKcWcUJZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Adding the Target to the Data Frame**\n",
        "\n",
        "We will add the target column from the dataset. We will call our target column 'label' with 0 and 1 representing malignant and benign, respectively\n"
      ],
      "metadata": {
        "id": "vEBc17WkqOIw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEvD_aTDiNLF"
      },
      "source": [
        "X['label'] = breast_cancer_data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization of our Data Frame**"
      ],
      "metadata": {
        "id": "8D4PYLZ7qXOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "aJz_NWuAULtD",
        "outputId": "cd75ecc0-a907-4a28-cce3-05883cd29c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                   0.07871  ...          17.33           184.60      2019.0   \n",
              "1                   0.05667  ...          23.41           158.80      1956.0   \n",
              "2                   0.05999  ...          25.53           152.50      1709.0   \n",
              "3                   0.09744  ...          26.50            98.87       567.7   \n",
              "4                   0.05883  ...          16.67           152.20      1575.0   \n",
              "..                      ...  ...            ...              ...         ...   \n",
              "564                 0.05623  ...          26.40           166.10      2027.0   \n",
              "565                 0.05533  ...          38.25           155.00      1731.0   \n",
              "566                 0.05648  ...          34.12           126.70      1124.0   \n",
              "567                 0.07016  ...          39.42           184.60      1821.0   \n",
              "568                 0.05884  ...          30.37            59.16       268.6   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "0             0.16220            0.66560           0.7119   \n",
              "1             0.12380            0.18660           0.2416   \n",
              "2             0.14440            0.42450           0.4504   \n",
              "3             0.20980            0.86630           0.6869   \n",
              "4             0.13740            0.20500           0.4000   \n",
              "..                ...                ...              ...   \n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
              "0                  0.2654          0.4601                  0.11890      0  \n",
              "1                  0.1860          0.2750                  0.08902      0  \n",
              "2                  0.2430          0.3613                  0.08758      0  \n",
              "3                  0.2575          0.6638                  0.17300      0  \n",
              "4                  0.1625          0.2364                  0.07678      0  \n",
              "..                    ...             ...                      ...    ...  \n",
              "564                0.2216          0.2060                  0.07115      0  \n",
              "565                0.1628          0.2572                  0.06637      0  \n",
              "566                0.1418          0.2218                  0.07820      0  \n",
              "567                0.2650          0.4087                  0.12400      0  \n",
              "568                0.0000          0.2871                  0.07039      1  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bb33c44-9fbf-4320-9b49-e959052e4fd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bb33c44-9fbf-4320-9b49-e959052e4fd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bb33c44-9fbf-4320-9b49-e959052e4fd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bb33c44-9fbf-4320-9b49-e959052e4fd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given our (30) features in the table above, the model will predict if the tumor is malignant or benign. We have 568 data points. \n",
        "\n",
        "1--> 357 Benign<br>\n",
        "0--> 212 Malignant \n",
        "\n",
        "We can check the distribution of our target variable to see how many subjects in each label. We want to make sure there isn't a huge imbalance in data points that are assigned to each category or the model will not train correctly."
      ],
      "metadata": {
        "id": "OiKWMCpgzUNS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC8Yii4Yjzer",
        "outputId": "b6c772f3-6087-472f-c3ef-f800749c2515"
      },
      "source": [
        "X['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Splitting the Data into Training and Testing Data**\n",
        "\n",
        "We will split the data using the train_test_split function. We will use a test size of 0.15 (15% percent of the data) and a random state of 1. We will also standardize the data using sklearn."
      ],
      "metadata": {
        "id": "ziuJYi1JUbGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=1)\n"
      ],
      "metadata": {
        "id": "s860ovinVmxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test size chosen was 15% of the data, or 86 points.\n",
        "Training will be done with 85% of the data, or 483 points."
      ],
      "metadata": {
        "id": "Wc284wyt3utn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHgIl7xqXIcd",
        "outputId": "7a869b25-8af9-4439-d57d-5e83d7111c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(483, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTtYlVNRXKve",
        "outputId": "c4a09fa0-726c-4bc4-8707-254d4190c4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also standardize the data using sklearn for optimal results."
      ],
      "metadata": {
        "id": "GptTsNa0W3yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_st = scaler.fit_transform(X_train)\n",
        "X_test_st = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "j152QtJ1_VEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Neural Network**<br>\n",
        "Using Keras and Tensor Flow\n",
        "\n",
        "![image](https://victorzhou.com/media/nn-series/network.svg)"
      ],
      "metadata": {
        "id": "cgeKUOR5Y57L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Defining a Neural Network Model**\n",
        "\n",
        "First we will beuild the layers of the neural network using the function keras.Sequential which groups a linear stack of layers into the model. Our input layer will be Flat, the hideen layer Dense, and the output layer Dense. 'Dense' means all neurons in the previous layer will be connected to the current layer.The purpose of 'Flatten' is to create an array that assigns one neuron to each feature."
      ],
      "metadata": {
        "id": "O1cq3eT8hur1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(30,))\n",
        "                          keras.layers.Dense(10, activation='relu')\n",
        "                          keras.layers.Dense(2, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "t9Q6YkOEXtqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Compiling the Model**\n"
      ],
      "metadata": {
        "id": "uXxFEbfqoAF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mgng6GpdX0kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Fitting the Model**"
      ],
      "metadata": {
        "id": "4o9ShmBqn_NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_st, Y_train, validation_split=0.1, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztBdR1ZQanli",
        "outputId": "027ddf06-49d6-403d-ecee-1c0dfe90ac67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 1s 22ms/step - loss: 0.8965 - accuracy: 0.5484 - val_loss: 1.0068 - val_accuracy: 0.5510\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6728 - val_loss: 0.7270 - val_accuracy: 0.6327\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7719 - val_loss: 0.5209 - val_accuracy: 0.7143\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8479 - val_loss: 0.3730 - val_accuracy: 0.8367\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.9217 - val_loss: 0.2722 - val_accuracy: 0.9184\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2045 - accuracy: 0.9631 - val_loss: 0.2006 - val_accuracy: 0.9184\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9770 - val_loss: 0.1525 - val_accuracy: 0.9592\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1236 - accuracy: 0.9816 - val_loss: 0.1220 - val_accuracy: 0.9796\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9908 - val_loss: 0.1019 - val_accuracy: 0.9796\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9931 - val_loss: 0.0892 - val_accuracy: 0.9796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We have a test accuracy of 99%\n",
        "#We have a validation accuracy of 97%"
      ],
      "metadata": {
        "id": "4AXyJuRGsDxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize the Results**"
      ],
      "metadata": {
        "id": "mg3v2SgUokp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=history.history[\"accuracy\"]\n",
        "val_accuracy=history.history[\"val_accuracy\"]\n",
        "plt.plot(test_accuracy)\n",
        "plt.plot(val_accuracy)\n",
        "plt.title('Testing and Validation Accuracy Over Time')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training data', 'Validation data'], loc = 'lower right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "OZwH60i8aqrU",
        "outputId": "2ebe3c70-264b-47a4-e0a7-2418591544a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fba36c09b20>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9: Perform Stratified K-Fold Cross Validation**"
      ],
      "metadata": {
        "id": "QjhUecoJosE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skf = KFold(n_splits=10, shuffle=True)\n",
        "skf.get_n_splits(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yHM9kr1bMrr",
        "outputId": "78dc59ae-6a88-4215-fb1a-01607f7e80f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = KFold(n_splits=10, shuffle=True)\n",
        "accuracy_list=[]\n",
        "for train, test in skf.split(X,Y):\n",
        "  history = model.fit(X.loc[train],Y[train],epochs=10,verbose=False)\n",
        "  Y_test_pred = model.predict(X.loc[test])\n",
        "  Y_pred_labels = [np.argmax(i) for i in Y_test_pred]\n",
        "  fold_accuracy=sum(Y_pred_labels==Y[test])/len(Y[test])\n",
        "  accuracy_list.append(fold_accuracy)\n",
        "print(accuracy_list)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-uHCMCiDVPf",
        "outputId": "7c86285f-6b4e-499c-a7bb-25bd692ef02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "[0.8245614035087719, 0.8771929824561403, 0.9122807017543859, 0.8771929824561403, 0.8596491228070176, 0.8245614035087719, 0.8771929824561403, 0.8947368421052632, 0.8947368421052632, 0.875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrDekIr0gA0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}